{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.identity = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        if self.identity is not None:\n",
    "            identity = self.identity(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M34(nn.Module):\n",
    "    def __init__(self,block, in_channels, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "\n",
    "        self.conv1 = nn.Conv1d(1, 48, kernel_size=160, stride=4)\n",
    "        self.bn1 = nn.BatchNorm1d(48)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(4)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, layers[0], 48, 48)\n",
    "        self.layer2 = self._make_layer(block, layers[1], 48, 96)\n",
    "        self.layer3 = self._make_layer(block, layers[2], 96, 192)\n",
    "        self.layer4 = self._make_layer(block, layers[3], 192, 384)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(384, 2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.relu(self.bn1(self.conv1(input)))\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, layer, in_channels, out_channels):\n",
    "        self.layer =layer\n",
    "        layers = []\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        identity_downsample = None\n",
    "\n",
    "        self.expansion = 2\n",
    "\n",
    "        \n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity_downsample  = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        layers.append(block(in_channels, out_channels, identity_downsample))\n",
    "        self.in_channels = self.out_channels\n",
    "            \n",
    "        for i in range(layer-1):\n",
    "            layers.append(block(self.in_channels, self.out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [3,4,6,3]\n",
    "model = M34(block, 1, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1            [-1, 48, 15961]           7,728\n",
      "       BatchNorm1d-2            [-1, 48, 15961]              96\n",
      "              ReLU-3            [-1, 48, 15961]               0\n",
      "         MaxPool1d-4             [-1, 48, 3990]               0\n",
      "            Conv1d-5             [-1, 48, 3990]           6,960\n",
      "       BatchNorm1d-6             [-1, 48, 3990]              96\n",
      "              ReLU-7             [-1, 48, 3990]               0\n",
      "            Conv1d-8             [-1, 48, 3990]           6,960\n",
      "       BatchNorm1d-9             [-1, 48, 3990]              96\n",
      "             ReLU-10             [-1, 48, 3990]               0\n",
      "            block-11             [-1, 48, 3990]               0\n",
      "           Conv1d-12             [-1, 48, 3990]           6,960\n",
      "      BatchNorm1d-13             [-1, 48, 3990]              96\n",
      "             ReLU-14             [-1, 48, 3990]               0\n",
      "           Conv1d-15             [-1, 48, 3990]           6,960\n",
      "      BatchNorm1d-16             [-1, 48, 3990]              96\n",
      "             ReLU-17             [-1, 48, 3990]               0\n",
      "            block-18             [-1, 48, 3990]               0\n",
      "           Conv1d-19             [-1, 48, 3990]           6,960\n",
      "      BatchNorm1d-20             [-1, 48, 3990]              96\n",
      "             ReLU-21             [-1, 48, 3990]               0\n",
      "           Conv1d-22             [-1, 48, 3990]           6,960\n",
      "      BatchNorm1d-23             [-1, 48, 3990]              96\n",
      "             ReLU-24             [-1, 48, 3990]               0\n",
      "            block-25             [-1, 48, 3990]               0\n",
      "        MaxPool1d-26              [-1, 48, 997]               0\n",
      "           Conv1d-27              [-1, 96, 997]          13,920\n",
      "      BatchNorm1d-28              [-1, 96, 997]             192\n",
      "             ReLU-29              [-1, 96, 997]               0\n",
      "           Conv1d-30              [-1, 96, 997]          27,744\n",
      "      BatchNorm1d-31              [-1, 96, 997]             192\n",
      "           Conv1d-32              [-1, 96, 997]           4,704\n",
      "      BatchNorm1d-33              [-1, 96, 997]             192\n",
      "             ReLU-34              [-1, 96, 997]               0\n",
      "            block-35              [-1, 96, 997]               0\n",
      "           Conv1d-36              [-1, 96, 997]          27,744\n",
      "      BatchNorm1d-37              [-1, 96, 997]             192\n",
      "             ReLU-38              [-1, 96, 997]               0\n",
      "           Conv1d-39              [-1, 96, 997]          27,744\n",
      "      BatchNorm1d-40              [-1, 96, 997]             192\n",
      "             ReLU-41              [-1, 96, 997]               0\n",
      "            block-42              [-1, 96, 997]               0\n",
      "           Conv1d-43              [-1, 96, 997]          27,744\n",
      "      BatchNorm1d-44              [-1, 96, 997]             192\n",
      "             ReLU-45              [-1, 96, 997]               0\n",
      "           Conv1d-46              [-1, 96, 997]          27,744\n",
      "      BatchNorm1d-47              [-1, 96, 997]             192\n",
      "             ReLU-48              [-1, 96, 997]               0\n",
      "            block-49              [-1, 96, 997]               0\n",
      "           Conv1d-50              [-1, 96, 997]          27,744\n",
      "      BatchNorm1d-51              [-1, 96, 997]             192\n",
      "             ReLU-52              [-1, 96, 997]               0\n",
      "           Conv1d-53              [-1, 96, 997]          27,744\n",
      "      BatchNorm1d-54              [-1, 96, 997]             192\n",
      "             ReLU-55              [-1, 96, 997]               0\n",
      "            block-56              [-1, 96, 997]               0\n",
      "        MaxPool1d-57              [-1, 96, 249]               0\n",
      "           Conv1d-58             [-1, 192, 249]          55,488\n",
      "      BatchNorm1d-59             [-1, 192, 249]             384\n",
      "             ReLU-60             [-1, 192, 249]               0\n",
      "           Conv1d-61             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-62             [-1, 192, 249]             384\n",
      "           Conv1d-63             [-1, 192, 249]          18,624\n",
      "      BatchNorm1d-64             [-1, 192, 249]             384\n",
      "             ReLU-65             [-1, 192, 249]               0\n",
      "            block-66             [-1, 192, 249]               0\n",
      "           Conv1d-67             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-68             [-1, 192, 249]             384\n",
      "             ReLU-69             [-1, 192, 249]               0\n",
      "           Conv1d-70             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-71             [-1, 192, 249]             384\n",
      "             ReLU-72             [-1, 192, 249]               0\n",
      "            block-73             [-1, 192, 249]               0\n",
      "           Conv1d-74             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-75             [-1, 192, 249]             384\n",
      "             ReLU-76             [-1, 192, 249]               0\n",
      "           Conv1d-77             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-78             [-1, 192, 249]             384\n",
      "             ReLU-79             [-1, 192, 249]               0\n",
      "            block-80             [-1, 192, 249]               0\n",
      "           Conv1d-81             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-82             [-1, 192, 249]             384\n",
      "             ReLU-83             [-1, 192, 249]               0\n",
      "           Conv1d-84             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-85             [-1, 192, 249]             384\n",
      "             ReLU-86             [-1, 192, 249]               0\n",
      "            block-87             [-1, 192, 249]               0\n",
      "           Conv1d-88             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-89             [-1, 192, 249]             384\n",
      "             ReLU-90             [-1, 192, 249]               0\n",
      "           Conv1d-91             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-92             [-1, 192, 249]             384\n",
      "             ReLU-93             [-1, 192, 249]               0\n",
      "            block-94             [-1, 192, 249]               0\n",
      "           Conv1d-95             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-96             [-1, 192, 249]             384\n",
      "             ReLU-97             [-1, 192, 249]               0\n",
      "           Conv1d-98             [-1, 192, 249]         110,784\n",
      "      BatchNorm1d-99             [-1, 192, 249]             384\n",
      "            ReLU-100             [-1, 192, 249]               0\n",
      "           block-101             [-1, 192, 249]               0\n",
      "       MaxPool1d-102              [-1, 192, 62]               0\n",
      "          Conv1d-103              [-1, 384, 62]         221,568\n",
      "     BatchNorm1d-104              [-1, 384, 62]             768\n",
      "            ReLU-105              [-1, 384, 62]               0\n",
      "          Conv1d-106              [-1, 384, 62]         442,752\n",
      "     BatchNorm1d-107              [-1, 384, 62]             768\n",
      "          Conv1d-108              [-1, 384, 62]          74,112\n",
      "     BatchNorm1d-109              [-1, 384, 62]             768\n",
      "            ReLU-110              [-1, 384, 62]               0\n",
      "           block-111              [-1, 384, 62]               0\n",
      "          Conv1d-112              [-1, 384, 62]         442,752\n",
      "     BatchNorm1d-113              [-1, 384, 62]             768\n",
      "            ReLU-114              [-1, 384, 62]               0\n",
      "          Conv1d-115              [-1, 384, 62]         442,752\n",
      "     BatchNorm1d-116              [-1, 384, 62]             768\n",
      "            ReLU-117              [-1, 384, 62]               0\n",
      "           block-118              [-1, 384, 62]               0\n",
      "          Conv1d-119              [-1, 384, 62]         442,752\n",
      "     BatchNorm1d-120              [-1, 384, 62]             768\n",
      "            ReLU-121              [-1, 384, 62]               0\n",
      "          Conv1d-122              [-1, 384, 62]         442,752\n",
      "     BatchNorm1d-123              [-1, 384, 62]             768\n",
      "            ReLU-124              [-1, 384, 62]               0\n",
      "           block-125              [-1, 384, 62]               0\n",
      "       MaxPool1d-126              [-1, 384, 15]               0\n",
      "AdaptiveAvgPool1d-127               [-1, 384, 1]               0\n",
      "         Flatten-128                  [-1, 384]               0\n",
      "          Linear-129                    [-1, 2]             770\n",
      "================================================================\n",
      "Total params: 4,078,034\n",
      "Trainable params: 4,078,034\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.24\n",
      "Forward/backward pass size (MB): 92.50\n",
      "Params size (MB): 15.56\n",
      "Estimated Total Size (MB): 108.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1,64000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fyp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fd12c0110a4e677020ed062760c440d27ea6b6f2cfce5522b10596f8f3a8860"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
